/**
 * Inflexion â€” RAG Vector Store (JSON-based)
 *
 * Store vectoriel lÃ©ger basÃ© sur des fichiers JSON.
 * Stocke les embeddings d'articles et de briefings pour permettre
 * la recherche par similaritÃ© sÃ©mantique.
 *
 * Architecture :
 *   data/rag/articles.json    â€” Embeddings des articles (news, RSS)
 *   data/rag/briefings.json   â€” Embeddings des briefings quotidiens
 *
 * Chaque entrÃ©e contient :
 *   { id, text, embedding, metadata, date }
 */

import { readFileSync, writeFileSync, existsSync, mkdirSync } from 'fs';
import { join } from 'path';

// â”€â”€â”€ SimilaritÃ© cosinus (inline pour Ã©viter la dÃ©pendance @xenova/transformers) â”€
/**
 * Calcule la similaritÃ© cosinus entre deux vecteurs.
 * @param {number[]} a â€” Vecteur A
 * @param {number[]} b â€” Vecteur B
 * @returns {number} â€” Score entre -1 et 1 (1 = identique)
 */
function cosineSimilarity(a, b) {
    if (!a || !b || a.length !== b.length) return 0;
    let dot = 0, normA = 0, normB = 0;
    for (let i = 0; i < a.length; i++) {
        dot += a[i] * b[i];
        normA += a[i] * a[i];
        normB += b[i] * b[i];
    }
    const denom = Math.sqrt(normA) * Math.sqrt(normB);
    return denom === 0 ? 0 : dot / denom;
}

// â”€â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const MAX_ARTICLES = 500;   // Garder les 500 derniers articles indexÃ©s
const MAX_BRIEFINGS = 60;   // Garder les 60 derniers briefings (~2 mois)

// â”€â”€â”€ Recherche hybride : pondÃ©ration vectoriel / lexical â”€â”€â”€â”€
// score_final = (cosinus * VECTOR_WEIGHT) + (lexical * KEYWORD_WEIGHT)
// Ajuster ces constantes pour calibrer l'importance relative.
export const VECTOR_WEIGHT = 0.7;
export const KEYWORD_WEIGHT = 0.3;

// â”€â”€â”€ Stopwords FR + EN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Mots de liaison ignorÃ©s lors de l'extraction de mots-clÃ©s.
const STOPWORDS = new Set([
    // FranÃ§ais
    'le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', 'ce', 'cette', 'ces',
    'et', 'ou', 'mais', 'donc', 'ni', 'car', 'que', 'qui', 'dont', 'oÃ¹',
    'dans', 'sur', 'sous', 'pour', 'par', 'avec', 'sans', 'entre', 'vers',
    'est', 'sont', 'Ãªtre', 'etre', 'avoir', 'fait', 'plus', 'trÃ¨s', 'tres',
    'pas', 'ne', 'se', 'son', 'sa', 'ses', 'leur', 'leurs', 'aux', 'au',
    'en', 'il', 'elle', 'on', 'nous', 'vous', 'ils', 'elles',
    // Anglais
    'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
    'should', 'may', 'might', 'shall', 'can', 'to', 'of', 'in', 'for',
    'on', 'with', 'at', 'by', 'from', 'as', 'into', 'about', 'after',
    'it', 'its', 'he', 'she', 'they', 'we', 'you', 'that', 'this',
    'which', 'who', 'whom', 'what', 'how', 'when', 'where', 'why',
    'not', 'no', 'but', 'or', 'and', 'if', 'then', 'so', 'than',
]);

// â”€â”€â”€ Fonctions de scoring lexical â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * Extrait les mots-clÃ©s significatifs d'un texte (sans stopwords).
 * @param {string} text â€” Texte brut (requÃªte ou document)
 * @returns {string[]} â€” Mots-clÃ©s en minuscules, dÃ©dupliquÃ©s
 */
export function extractKeywords(text) {
    if (!text || typeof text !== 'string') return [];
    return [...new Set(
        text
            .toLowerCase()
            .normalize('NFD').replace(/[\u0300-\u036f]/g, '')  // retirer accents
            .split(/[^a-z0-9Ã Ã¢Ã¤Ã©Ã¨ÃªÃ«Ã¯Ã®Ã´Ã¹Ã»Ã¼Ã§Ã¦Å“&$/%-]+/i)
            .map(w => w.trim())
            .filter(w => w.length >= 2 && !STOPWORDS.has(w))
    )];
}

/**
 * Calcule un score lexical (0-1) entre mots-clÃ©s de la requÃªte et le texte d'un document.
 * Utilise des word boundaries (\b) pour les mots courts (â‰¤4 car.) afin d'Ã©viter
 * les faux positifs (ex: "or" ne matche pas "Chamfort").
 *
 * @param {string[]} queryKeywords â€” Mots-clÃ©s extraits de la requÃªte
 * @param {string} docText â€” Texte brut du document (title + description)
 * @returns {number} â€” Score entre 0 et 1
 */
export function keywordScore(queryKeywords, docText) {
    if (!queryKeywords.length || !docText) return 0;

    const normalizedDoc = docText
        .toLowerCase()
        .normalize('NFD').replace(/[\u0300-\u036f]/g, '');

    let matches = 0;
    for (const kw of queryKeywords) {
        if (kw.length <= 4) {
            // Word boundary pour les mots courts â€” Ã©vite les faux positifs
            const regex = new RegExp(`\\b${kw.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')}\\b`, 'i');
            if (regex.test(normalizedDoc)) matches++;
        } else {
            // Substring matching suffit pour les mots longs (>4 car.)
            if (normalizedDoc.includes(kw)) matches++;
        }
    }

    return matches / queryKeywords.length;
}

// â”€â”€â”€ Utilitaires I/O â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function loadStore(filepath) {
    if (!existsSync(filepath)) return [];
    try {
        return JSON.parse(readFileSync(filepath, 'utf-8'));
    } catch {
        console.warn(`  âš  Fichier RAG corrompu: ${filepath}, rÃ©initialisation`);
        return [];
    }
}

function saveStore(filepath, entries) {
    const dir = join(filepath, '..');
    if (!existsSync(dir)) mkdirSync(dir, { recursive: true });
    writeFileSync(filepath, JSON.stringify(entries), 'utf-8');
}

// â”€â”€â”€ RAGStore class â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export class RAGStore {
    /**
     * @param {string} ragDir â€” Chemin vers le dossier data/rag/
     */
    constructor(ragDir) {
        this.ragDir = ragDir;
        this.articlesPath = join(ragDir, 'articles.json');
        this.briefingsPath = join(ragDir, 'briefings.json');

        // CrÃ©er le dossier si nÃ©cessaire
        if (!existsSync(ragDir)) {
            mkdirSync(ragDir, { recursive: true });
        }
    }

    // â”€â”€â”€ Articles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * Charge les articles indexÃ©s.
     * @returns {Array}
     */
    loadArticles() {
        return loadStore(this.articlesPath);
    }

    /**
     * Ajoute des articles au store (dÃ©dupliquÃ©s par ID).
     * @param {Array<{id: string, text: string, embedding: number[], metadata: Object, date: string}>} newEntries
     */
    addArticles(newEntries) {
        const existing = this.loadArticles();
        const existingIds = new Set(existing.map(e => e.id));

        let added = 0;
        for (const entry of newEntries) {
            if (!existingIds.has(entry.id)) {
                existing.push(entry);
                existingIds.add(entry.id);
                added++;
            }
        }

        // Trier par date dÃ©croissante et garder les N plus rÃ©cents
        existing.sort((a, b) => (b.date || '').localeCompare(a.date || ''));
        const trimmed = existing.slice(0, MAX_ARTICLES);

        saveStore(this.articlesPath, trimmed);
        console.log(`  ðŸ“š Articles RAG: +${added} ajoutÃ©s, ${trimmed.length} total (max ${MAX_ARTICLES})`);
        return added;
    }

    /**
     * Recherche les articles les plus similaires Ã  un vecteur query.
     * Mode hybride : si queryText est fourni, combine score vectoriel
     * et score lexical (mots-clÃ©s) pour mieux remonter les acronymes,
     * tickers et noms propres.
     *
     * @param {number[]} queryEmbedding â€” Vecteur de recherche
     * @param {Object} [options]
     * @param {number} [options.topK=5] â€” Nombre de rÃ©sultats
     * @param {number} [options.minScore=0.3] â€” Score minimum de similaritÃ©
     * @param {string} [options.excludeDate] â€” Exclure les articles de cette date
     * @param {string} [options.queryText] â€” Texte brut de la requÃªte (active le scoring hybride)
     * @returns {Array<{entry: Object, score: number}>}
     */
    searchArticles(queryEmbedding, options = {}) {
        const { topK = 5, minScore = 0.3, excludeDate = null, queryText = null } = options;
        const articles = this.loadArticles();
        const qKeywords = queryText ? extractKeywords(queryText) : [];

        const scored = articles
            .filter(a => !excludeDate || a.date !== excludeDate)
            .map(entry => {
                const vectorScore = cosineSimilarity(queryEmbedding, entry.embedding);
                if (!qKeywords.length) {
                    return { entry, score: vectorScore };
                }
                const kwScore = keywordScore(qKeywords, entry.text);
                return {
                    entry,
                    score: (vectorScore * VECTOR_WEIGHT) + (kwScore * KEYWORD_WEIGHT),
                };
            })
            .filter(r => r.score >= minScore)
            .sort((a, b) => b.score - a.score)
            .slice(0, topK);

        return scored;
    }

    // â”€â”€â”€ Briefings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * Charge les briefings indexÃ©s.
     * @returns {Array}
     */
    loadBriefings() {
        return loadStore(this.briefingsPath);
    }

    /**
     * Ajoute un briefing au store.
     * @param {{id: string, text: string, embedding: number[], metadata: Object, date: string}} entry
     */
    addBriefing(entry) {
        const existing = this.loadBriefings();
        const existingIds = new Set(existing.map(e => e.id));

        if (existingIds.has(entry.id)) {
            // Mettre Ã  jour l'existant
            const idx = existing.findIndex(e => e.id === entry.id);
            existing[idx] = entry;
        } else {
            existing.push(entry);
        }

        // Trier par date et garder les N plus rÃ©cents
        existing.sort((a, b) => (b.date || '').localeCompare(a.date || ''));
        const trimmed = existing.slice(0, MAX_BRIEFINGS);

        saveStore(this.briefingsPath, trimmed);
        return true;
    }

    /**
     * Recherche les briefings les plus similaires Ã  un vecteur query.
     * Mode hybride : si queryText est fourni, combine score vectoriel
     * et score lexical.
     *
     * @param {number[]} queryEmbedding â€” Vecteur de recherche
     * @param {Object} [options]
     * @param {number} [options.topK=3] â€” Nombre de rÃ©sultats
     * @param {number} [options.minScore=0.25] â€” Score minimum
     * @param {string} [options.excludeDate] â€” Exclure le briefing de cette date
     * @param {string} [options.queryText] â€” Texte brut de la requÃªte (active le scoring hybride)
     * @returns {Array<{entry: Object, score: number}>}
     */
    searchBriefings(queryEmbedding, options = {}) {
        const { topK = 3, minScore = 0.25, excludeDate = null, queryText = null } = options;
        const briefings = this.loadBriefings();
        const qKeywords = queryText ? extractKeywords(queryText) : [];

        const scored = briefings
            .filter(b => !excludeDate || b.date !== excludeDate)
            .map(entry => {
                const vectorScore = cosineSimilarity(queryEmbedding, entry.embedding);
                if (!qKeywords.length) {
                    return { entry, score: vectorScore };
                }
                const kwScore = keywordScore(qKeywords, entry.text);
                return {
                    entry,
                    score: (vectorScore * VECTOR_WEIGHT) + (kwScore * KEYWORD_WEIGHT),
                };
            })
            .filter(r => r.score >= minScore)
            .sort((a, b) => b.score - a.score)
            .slice(0, topK);

        return scored;
    }

    /**
     * Retourne les N derniers briefings (par date, sans similaritÃ©).
     * @param {number} [n=3] â€” Nombre de briefings rÃ©cents
     * @param {string} [excludeDate] â€” Date Ã  exclure
     * @returns {Array}
     */
    getRecentBriefings(n = 3, excludeDate = null) {
        const briefings = this.loadBriefings();
        return briefings
            .filter(b => !excludeDate || b.date !== excludeDate)
            .slice(0, n);
    }

    // â”€â”€â”€ Stats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * Retourne les statistiques du store.
     */
    getStats() {
        const articles = this.loadArticles();
        const briefings = this.loadBriefings();
        return {
            articlesCount: articles.length,
            briefingsCount: briefings.length,
            oldestArticle: articles[articles.length - 1]?.date || null,
            newestArticle: articles[0]?.date || null,
            oldestBriefing: briefings[briefings.length - 1]?.date || null,
            newestBriefing: briefings[0]?.date || null,
        };
    }
}
